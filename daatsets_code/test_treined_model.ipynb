{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обробка зображення на навченій моделі"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2024-11-06T21:25:24.697737Z",
     "iopub.status.busy": "2024-11-06T21:25:24.697272Z",
     "iopub.status.idle": "2024-11-06T21:25:38.337275Z",
     "shell.execute_reply": "2024-11-06T21:25:38.336305Z",
     "shell.execute_reply.started": "2024-11-06T21:25:24.697698Z"
    },
    "id": "ZbNzsqKRoNO5",
    "outputId": "93e9da55-0126-4307-bf7d-f4e8d8c67297",
    "scrolled": true,
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 C:\\Users\\dimag\\Desktop\\6268353d59de8f00070b329c.tif: 1024x1024 5 Barges, 8 Ferrys, 2 Container Ships, 3 Shipping container lots, 3577.7ms\n",
      "Speed: 14.9ms preprocess, 3577.7ms inference, 11.0ms postprocess per image at shape (1, 3, 1024, 1024)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "\n",
    "image = r\"C:\\Users\\dimag\\Desktop\\6268353d59de8f00070b329c.tif\"\n",
    "\n",
    "img = cv2.imread(image)\n",
    "height, width = img.shape[:2]\n",
    "max_side = max(width, height)\n",
    "if max_side > 4096:\n",
    "    max_side = 1024\n",
    "\n",
    "model = YOLO(r\"\\\\RANOBEWORLD\\RanobeWorld-Disk\\Files\\Datasets\\xview_datasets\\yolo_xview_trained_model_newDataset_50ep.pt\")\n",
    "results = model.predict(source=image, imgsz=max_side, conf=0.2)\n",
    "\n",
    "for box in results[0].boxes:\n",
    "    x1, y1, x2, y2 = map(int, box.xyxy[0]) \n",
    "    class_name = model.names[int(box.cls[0])]\n",
    "    confidence = box.conf[0]  \n",
    "\n",
    "    label = f\"{class_name} {confidence:.2f}\"\n",
    "\n",
    "    cv2.rectangle(img, (x1, y1), (x2, y2), color=(0, 255, 0), thickness=1)  # Тонка рамка\n",
    "    cv2.putText(img, label, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.4, (255, 255, 255), 1)  # Невеликий шрифт\n",
    "\n",
    "\n",
    "cv2.imwrite(r\"C:\\Users\\dimag\\Desktop\\4789789.jpg\", img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Тайлова обробка зображення"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from ultralytics import YOLO\n",
    "from collections import defaultdict\n",
    "\n",
    "model = YOLO(r\"C:\\Users\\dimag\\Desktop\\yolo_xview_trained_model_newDataset_50ep.pt\")\n",
    "\n",
    "tile_size = 2048\n",
    "overlap = 0.1\n",
    "confidence_threshold = 0.1\n",
    "\n",
    "def get_tiles(image, tile_size, overlap):\n",
    "    height, width = image.shape[:2]\n",
    "    step = int(tile_size * (1 - overlap))\n",
    "    tiles = []\n",
    "    positions = []\n",
    "    \n",
    "    for y in range(0, height, step):\n",
    "        for x in range(0, width, step):\n",
    "            x_end = min(x + tile_size, width)\n",
    "            y_end = min(y + tile_size, height)\n",
    "            tile = image[y:y_end, x:x_end]\n",
    "            tiles.append(tile)\n",
    "            positions.append((x, y, x_end, y_end))\n",
    "    \n",
    "    return tiles, positions\n",
    "\n",
    "\n",
    "def process_tile(tile, position, model):\n",
    "    x_offset, y_offset = position[:2]\n",
    "    results = model.predict(source=tile, imgsz=tile.shape[1], conf=confidence_threshold)\n",
    "    detections = []\n",
    "    \n",
    "    for box in results[0].boxes:\n",
    "        confidence = box.conf[0]\n",
    "        if confidence >= confidence_threshold:\n",
    "            x1, y1, x2, y2 = map(int, box.xyxy[0])\n",
    "            class_id = int(box.cls[0])\n",
    "            detections.append({\n",
    "                \"coords\": (x1 + x_offset, y1 + y_offset, x2 + x_offset, y2 + y_offset),\n",
    "                \"class_id\": class_id,\n",
    "                \"confidence\": confidence\n",
    "            })\n",
    "    \n",
    "    return detections\n",
    "\n",
    "\n",
    "def process_large_image(image_path):\n",
    "\n",
    "    image = cv2.imread(image_path)\n",
    "    height, width = image.shape[:2]\n",
    "\n",
    "    tiles, positions = get_tiles(image, tile_size, overlap)\n",
    "\n",
    "    all_detections = []\n",
    "\n",
    "    for tile, position in zip(tiles, positions):\n",
    "        detections = process_tile(tile, position, model)\n",
    "        all_detections.extend(detections)\n",
    "\n",
    "    unique_detections = []\n",
    "    counted_coords = set()\n",
    "    for detection in all_detections:\n",
    "        x1, y1, x2, y2 = detection[\"coords\"]\n",
    "        if (x1, y1, x2, y2) not in counted_coords:\n",
    "            unique_detections.append(detection)\n",
    "            counted_coords.add((x1, y1, x2, y2))\n",
    "\n",
    "    class_counts = defaultdict(int)\n",
    "    for detection in unique_detections:\n",
    "        x1, y1, x2, y2 = detection[\"coords\"]\n",
    "        class_id = detection[\"class_id\"]\n",
    "        class_name = model.names[class_id]\n",
    "        confidence = detection[\"confidence\"]\n",
    "\n",
    "        cv2.rectangle(image, (x1, y1), (x2, y2), color=(0, 255, 0), thickness=1)\n",
    "        label = f\"{class_name} {confidence:.2f}\"\n",
    "        cv2.putText(image, label, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.4, (255, 255, 255), 1)\n",
    "\n",
    "        class_counts[class_name] += 1\n",
    "\n",
    "\n",
    "    output_path = r\"C:\\Users\\dimag\\Desktop\\output_with_detections.jpg\"\n",
    "    cv2.imwrite(output_path, image)\n",
    "\n",
    "    total_count = len(unique_detections)\n",
    "    print(f\"Общее количество объектов: {total_count}\")\n",
    "    for class_name, count in class_counts.items():\n",
    "        print(f\"{class_name}: {count}\")\n",
    "\n",
    "    return output_path\n",
    "\n",
    "image_path = r\"C:\\Users\\dimag\\Desktop\\олд\\24bfc3f8-1ff1-47dd-b06a-7e8f95a57c5f.tif\"\n",
    "output_image_path = process_large_image(image_path)\n",
    "print(f\"Результат збережено в {output_image_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 2048x2048 (no detections), 17258.0ms\n",
      "Speed: 34.4ms preprocess, 17258.0ms inference, 22.0ms postprocess per image at shape (1, 3, 2048, 2048)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 124\u001b[0m\n\u001b[0;32m    122\u001b[0m \u001b[38;5;66;03m# Путь к изображению\u001b[39;00m\n\u001b[0;32m    123\u001b[0m image_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mC:\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mUsers\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mdimag\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mDesktop\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124m24bfc3f8-1ff1-47dd-b06a-7e8f95a57c5f.tif\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m--> 124\u001b[0m output_image_path \u001b[38;5;241m=\u001b[39m \u001b[43mprocess_large_image\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    125\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mРезультат сохранен в \u001b[39m\u001b[38;5;132;01m{\u001b[39;00moutput_image_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[2], line 68\u001b[0m, in \u001b[0;36mprocess_large_image\u001b[1;34m(image_path)\u001b[0m\n\u001b[0;32m     66\u001b[0m \u001b[38;5;66;03m# Обрабатываем каждый тайл\u001b[39;00m\n\u001b[0;32m     67\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, (tile, position) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mzip\u001b[39m(tiles, positions)):\n\u001b[1;32m---> 68\u001b[0m     detections \u001b[38;5;241m=\u001b[39m \u001b[43mprocess_tile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mposition\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     69\u001b[0m     all_detections\u001b[38;5;241m.\u001b[39mextend(detections)\n\u001b[0;32m     71\u001b[0m     \u001b[38;5;66;03m# Сохраняем обработанный тайл в папку\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[2], line 40\u001b[0m, in \u001b[0;36mprocess_tile\u001b[1;34m(tile, position, model)\u001b[0m\n\u001b[0;32m     37\u001b[0m results \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(source\u001b[38;5;241m=\u001b[39mtile, imgsz\u001b[38;5;241m=\u001b[39mtile_size, conf\u001b[38;5;241m=\u001b[39mconfidence_threshold)\n\u001b[0;32m     38\u001b[0m detections \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m---> 40\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbox\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mresults\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mboxes\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m     41\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconfidence\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mbox\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[0;32m     42\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mconfidence\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m>\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mconfidence_threshold\u001b[49m\u001b[43m:\u001b[49m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'NoneType' object is not iterable"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from ultralytics import YOLO\n",
    "from collections import defaultdict\n",
    "\n",
    "\n",
    "model = YOLO(r\"C:\\Users\\dimag\\Desktop\\detect_results_dota_big_3ep\\obb\\train6\\weights\\best.pt\")\n",
    "\n",
    "tile_size = 2048\n",
    "overlap = 0.2  \n",
    "confidence_threshold = 0.1\n",
    "output_tile_dir = os.path.join(os.getcwd(), \"test_tiles\")\n",
    "os.makedirs(output_tile_dir, exist_ok=True)\n",
    "\n",
    "\n",
    "def get_tiles_with_overlap(image, tile_size, overlap):\n",
    "    height, width = image.shape[:2]\n",
    "    step = int(tile_size * (1 - overlap))\n",
    "    tiles = []\n",
    "    positions = []\n",
    "    \n",
    "    for y in range(0, height, step):\n",
    "        for x in range(0, width, step):\n",
    "            x_end = min(x + tile_size, width)\n",
    "            y_end = min(y + tile_size, height)\n",
    "            tile = image[y:y_end, x:x_end]\n",
    "            tiles.append(tile)\n",
    "            positions.append((x, y, x_end, y_end))\n",
    "    \n",
    "    return tiles, positions\n",
    "\n",
    "\n",
    "def process_tile(tile, position, model):\n",
    "    x_offset, y_offset = position[:2]\n",
    "    results = model.predict(source=tile, imgsz=tile_size, conf=confidence_threshold)\n",
    "    detections = []\n",
    "    \n",
    "    for box in results[0].boxes:\n",
    "        confidence = box.conf[0]\n",
    "        if confidence >= confidence_threshold:\n",
    "            x1, y1, x2, y2 = map(int, box.xyxy[0])\n",
    "            class_id = int(box.cls[0])\n",
    "\n",
    "            detections.append({\n",
    "                \"coords\": (x1 + x_offset, y1 + y_offset, x2 + x_offset, y2 + y_offset),\n",
    "                \"class_id\": class_id,\n",
    "                \"confidence\": confidence\n",
    "            })\n",
    "    \n",
    "    return detections\n",
    "\n",
    "\n",
    "def process_large_image(image_path):\n",
    "    image = cv2.imread(image_path)\n",
    "    height, width = image.shape[:2]\n",
    "\n",
    "    tiles, positions = get_tiles_with_overlap(image, tile_size, overlap)\n",
    "\n",
    "    all_detections = []\n",
    "\n",
    "    for i, (tile, position) in enumerate(zip(tiles, positions)):\n",
    "        detections = process_tile(tile, position, model)\n",
    "        all_detections.extend(detections)\n",
    "\n",
    "        tile_path = os.path.join(output_tile_dir, f\"tile_{i}.jpg\")\n",
    "        for detection in detections:\n",
    "            x1, y1, x2, y2 = detection[\"coords\"]\n",
    "            cv2.rectangle(tile, (x1 - position[0], y1 - position[1]), \n",
    "                          (x2 - position[0], y2 - position[1]), \n",
    "                          color=(0, 255, 0), thickness=1)\n",
    "            label = f\"{model.names[detection['class_id']]} {detection['confidence']:.2f}\"\n",
    "            cv2.putText(tile, label, (x1 - position[0], y1 - position[1] - 10), \n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.4, (255, 255, 255), 1)\n",
    "        cv2.imwrite(tile_path, tile)\n",
    "\n",
    "    unique_detections = []\n",
    "    counted_coords = set()\n",
    "    for detection in all_detections:\n",
    "        x1, y1, x2, y2 = detection[\"coords\"]\n",
    "        bbox_key = (round(x1 / tile_size), round(y1 / tile_size), \n",
    "                    round(x2 / tile_size), round(y2 / tile_size))\n",
    "        if bbox_key not in counted_coords:\n",
    "            unique_detections.append(detection)\n",
    "            counted_coords.add(bbox_key)\n",
    "\n",
    "    class_counts = defaultdict(int)\n",
    "    for detection in unique_detections:\n",
    "        x1, y1, x2, y2 = detection[\"coords\"]\n",
    "        class_id = detection[\"class_id\"]\n",
    "        class_name = model.names[class_id]\n",
    "        confidence = detection[\"confidence\"]\n",
    "\n",
    "        cv2.rectangle(image, (x1, y1), (x2, y2), color=(0, 255, 0), thickness=1)\n",
    "        label = f\"{class_name} {confidence:.2f}\"\n",
    "        cv2.putText(image, label, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.4, (255, 255, 255), 1)\n",
    "\n",
    "        class_counts[class_name] += 1\n",
    "\n",
    "    output_image_path = r\"C:\\Users\\dimag\\Desktop\\output_with_detections.jpg\"\n",
    "    cv2.imwrite(output_image_path, image)\n",
    "\n",
    "    total_count = len(unique_detections)\n",
    "    print(f\"Общее количество объектов: {total_count}\")\n",
    "    for class_name, count in class_counts.items():\n",
    "        print(f\"{class_name}: {count}\")\n",
    "\n",
    "    return output_image_path\n",
    "\n",
    "image_path = r\"C:\\Users\\dimag\\Desktop\\24bfc3f8-1ff1-47dd-b06a-7e8f95a57c5f.tif\"\n",
    "output_image_path = process_large_image(image_path)\n",
    "print(f\"Результат сохранен в {output_image_path}\")\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 3649216,
     "sourceId": 6633966,
     "sourceType": "datasetVersion"
    },
    {
     "sourceId": 145625572,
     "sourceType": "kernelVersion"
    }
   ],
   "dockerImageVersionId": 30787,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
